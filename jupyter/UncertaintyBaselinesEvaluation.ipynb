{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02704f6e-2a29-45ba-afb6-fb67aa367a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from scipy.special import kl_div\n",
    "from functools import reduce\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import warnings\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from scipy.stats import entropy\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac9f7d3-6976-4ec4-930d-b5d13fd58508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63d1d9-08b7-4cac-ae6f-34e05e3c2ab0",
   "metadata": {},
   "source": [
    "# Baseline 1: Ensemble of Adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47abbcaf-8d2f-4122-a3e6-44aece33042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_files = glob.glob('/users/lucelo/UQLRM/metadata_single_mlp_*.tsv')\n",
    "reward_dfs = []\n",
    "for file in reward_files:\n",
    "    df = pd.read_csv(file, sep='\\t', header=0)[['id', 'RewardScore', 'Dataset', 'Preference']]\n",
    "    chosen_df = df[df['Preference'] == 'chosen'].rename(columns={'RewardScore': 'RewardChosen'})\n",
    "    rejected_df = df[df['Preference'] == 'rejected'].rename(columns={'RewardScore': 'RewardRejected'})\n",
    "    merged_df = chosen_df.merge(rejected_df, on=['id', 'Dataset'], how='inner')\n",
    "    merged_df['RewardDiff'] = merged_df['RewardChosen'] - merged_df['RewardRejected']\n",
    "    merged_df['PreferenceProb'] = sigmoid(merged_df['RewardDiff'])\n",
    "    reward_dfs.append(merged_df)\n",
    "\n",
    "for i, df in enumerate(reward_dfs):\n",
    "    # Add unique suffixes to the column names\n",
    "    df.columns = [f\"{col}_{i}\" if col != 'id' else col for col in df.columns]\n",
    "\n",
    "final_rewards =  pd.concat(reward_dfs, axis=1)\n",
    "N = len(reward_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98ad714a-0fb7-445f-8a8a-8f9f1d0d8c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 16123/16123 [02:19<00:00, 115.86it/s]\n"
     ]
    }
   ],
   "source": [
    "def compute_rw_distinct_pairs(final_rewards, N):\n",
    "    pairs = [(i, j) for i in range(N) for j in range(N)]\n",
    "    def compute_rw_diff_pairs(x):\n",
    "        # np.random.shuffle(pairs)\n",
    "        # pairs = pairs[:N]\n",
    "        diffs = []\n",
    "        for pair in pairs:\n",
    "            i,j = pair\n",
    "            diffs.append(x[f'RewardChosen_{i}'] - x[f'RewardRejected_{j}'])\n",
    "        return np.var(diffs)\n",
    "        \n",
    "    return final_rewards.progress_apply(lambda x: compute_rw_diff_pairs(x), axis=1)\n",
    "\n",
    "final_rewards['RwDiffDistinctPairs'] = compute_rw_distinct_pairs(final_rewards, len(reward_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89d20a9e-9998-4758-a724-fcf931bb76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reward_covariance(final_rewards):\n",
    "    covariances = []\n",
    "    for index, row in final_rewards.iterrows():\n",
    "        rejected = [row[f'RewardRejected_{n}'] for n in range(len(reward_dfs))]\n",
    "        chosen = [row[f'RewardChosen_{i}'] for i in range(len(reward_dfs))]\n",
    "        covariance = np.cov(rejected, chosen)[0][1]\n",
    "        covariances.append(covariance)\n",
    "    return covariances\n",
    "\n",
    "final_rewards['Covariance'] = compute_reward_covariance(final_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d87be29-37d8-48be-8c66-f99117ca4176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unc_stats(final_rewards):\n",
    "    # 1. Reward Statistics\n",
    "    final_rewards['RwAverage'] = final_rewards.filter(like=\"Reward\", axis=1).mean(axis=1)\n",
    "    final_rewards['RwVariance'] = final_rewards.filter(like=\"Reward\", axis=1).var(axis=1)\n",
    "    \n",
    "    # 2. \"Chosen\" Reward Statistics\n",
    "    final_rewards['RwChosenAverage'] = final_rewards.filter(like=\"RewardChosen\", axis=1).mean(axis=1)\n",
    "    final_rewards['RwChosenVariance'] = final_rewards.filter(like=\"RewardChosen\", axis=1).var(axis=1)\n",
    "    \n",
    "    # 3. \"Rejected\" Reward Statistics\n",
    "    final_rewards['RwRejectedAverage'] = final_rewards.filter(like=\"RewardRejected\", axis=1).mean(axis=1)\n",
    "    final_rewards['RwRejectedVariance'] = final_rewards.filter(like=\"RewardRejected\", axis=1).var(axis=1)\n",
    "    \n",
    "    # 4. Reward Diff (r_chosen - r_rejected) Statistics\n",
    "    final_rewards['RwDiffAverage'] = final_rewards.filter(like=\"RewardDiff\", axis=1).mean(axis=1)\n",
    "    final_rewards['RwDiffVariance'] = final_rewards.filter(like=\"RewardDiff\", axis=1).var(axis=1)\n",
    "    \n",
    "    # 5. Variance Sum = Var(r_chosen) + Var(r_rejected)\n",
    "    final_rewards['RwVarianceSum'] = final_rewards['RwChosenVariance'] + final_rewards['RwRejectedVariance']\n",
    "    \n",
    "    # 6. Var(r_chosen, r_rejected) = Var(r_chosen) - Var(r_rejected) - 2*Cov(r_chosen, r_rejected)\n",
    "    # This is an analytical version of Variance computed in #4\n",
    "    final_rewards['RwDiffAnalyticalVariance'] = final_rewards['RwChosenVariance'] + final_rewards['RwRejectedVariance'] - 2*final_rewards['Covariance']\n",
    "    \n",
    "    # 7. Var(p), p = sigmoid(r_chosen - r_rejected) (Preference Probability)\n",
    "    final_rewards['PrefProbVariance'] = final_rewards.filter(like=\"PreferenceProb\", axis=1).var(axis=1)\n",
    "    final_rewards['PrefProbAverage'] = final_rewards.filter(like=\"PreferenceProb\", axis=1).mean(axis=1)\n",
    "    \n",
    "    # 8. Max Variance = max(Var(r_chosen), Var(r_rejected))\n",
    "    final_rewards['RewardMaxVariance'] = final_rewards[['RwChosenVariance', 'RwRejectedVariance']].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab2b7c92-16b8-4e47-97e0-90caa2eae82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_unc_stats(final_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "517f05ad-103a-476c-8ac8-247085fe1cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>RewardChosen_0</th>\n",
       "      <th>Dataset_0</th>\n",
       "      <th>Preference_x_0</th>\n",
       "      <th>RewardRejected_0</th>\n",
       "      <th>Preference_y_0</th>\n",
       "      <th>RewardDiff_0</th>\n",
       "      <th>PreferenceProb_0</th>\n",
       "      <th>id</th>\n",
       "      <th>RewardChosen_1</th>\n",
       "      <th>...</th>\n",
       "      <th>RwChosenVariance</th>\n",
       "      <th>RwRejectedAverage</th>\n",
       "      <th>RwRejectedVariance</th>\n",
       "      <th>RwDiffAverage</th>\n",
       "      <th>RwDiffVariance</th>\n",
       "      <th>RwVarianceSum</th>\n",
       "      <th>RwDiffAnalyticalVariance</th>\n",
       "      <th>PrefProbVariance</th>\n",
       "      <th>PrefProbAverage</th>\n",
       "      <th>RewardMaxVariance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1801</td>\n",
       "      <td>-1.021655</td>\n",
       "      <td>train</td>\n",
       "      <td>chosen</td>\n",
       "      <td>-1.308317</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.286662</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>1801</td>\n",
       "      <td>-1.198608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018304</td>\n",
       "      <td>-1.222914</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>0.259599</td>\n",
       "      <td>0.029189</td>\n",
       "      <td>0.042980</td>\n",
       "      <td>0.029189</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.564097</td>\n",
       "      <td>0.024675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87053</td>\n",
       "      <td>1.413000</td>\n",
       "      <td>train</td>\n",
       "      <td>chosen</td>\n",
       "      <td>-0.526894</td>\n",
       "      <td>rejected</td>\n",
       "      <td>1.939894</td>\n",
       "      <td>0.874340</td>\n",
       "      <td>87053</td>\n",
       "      <td>1.505481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018581</td>\n",
       "      <td>-0.579809</td>\n",
       "      <td>0.024868</td>\n",
       "      <td>1.808733</td>\n",
       "      <td>0.019871</td>\n",
       "      <td>0.043450</td>\n",
       "      <td>0.019871</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.858371</td>\n",
       "      <td>0.024868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59149</td>\n",
       "      <td>-0.104880</td>\n",
       "      <td>train</td>\n",
       "      <td>chosen</td>\n",
       "      <td>-0.680847</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.575967</td>\n",
       "      <td>0.640139</td>\n",
       "      <td>59149</td>\n",
       "      <td>0.134865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021960</td>\n",
       "      <td>-0.488183</td>\n",
       "      <td>0.020723</td>\n",
       "      <td>0.620937</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.042683</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.649819</td>\n",
       "      <td>0.021960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20080</td>\n",
       "      <td>1.230862</td>\n",
       "      <td>train</td>\n",
       "      <td>chosen</td>\n",
       "      <td>-2.328661</td>\n",
       "      <td>rejected</td>\n",
       "      <td>3.559523</td>\n",
       "      <td>0.972335</td>\n",
       "      <td>20080</td>\n",
       "      <td>1.231286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016546</td>\n",
       "      <td>-2.121717</td>\n",
       "      <td>0.018112</td>\n",
       "      <td>3.213534</td>\n",
       "      <td>0.030726</td>\n",
       "      <td>0.034659</td>\n",
       "      <td>0.030726</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.960816</td>\n",
       "      <td>0.018112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72323</td>\n",
       "      <td>0.448723</td>\n",
       "      <td>train</td>\n",
       "      <td>chosen</td>\n",
       "      <td>-0.174440</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.623163</td>\n",
       "      <td>0.650938</td>\n",
       "      <td>72323</td>\n",
       "      <td>0.188774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026763</td>\n",
       "      <td>-0.180517</td>\n",
       "      <td>0.026328</td>\n",
       "      <td>0.469449</td>\n",
       "      <td>0.035856</td>\n",
       "      <td>0.053090</td>\n",
       "      <td>0.035856</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.614342</td>\n",
       "      <td>0.026763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 311 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  RewardChosen_0 Dataset_0 Preference_x_0  RewardRejected_0  \\\n",
       "0   1801       -1.021655     train         chosen         -1.308317   \n",
       "1  87053        1.413000     train         chosen         -0.526894   \n",
       "2  59149       -0.104880     train         chosen         -0.680847   \n",
       "3  20080        1.230862     train         chosen         -2.328661   \n",
       "4  72323        0.448723     train         chosen         -0.174440   \n",
       "\n",
       "  Preference_y_0  RewardDiff_0  PreferenceProb_0     id  RewardChosen_1  ...  \\\n",
       "0       rejected      0.286662          0.571179   1801       -1.198608  ...   \n",
       "1       rejected      1.939894          0.874340  87053        1.505481  ...   \n",
       "2       rejected      0.575967          0.640139  59149        0.134865  ...   \n",
       "3       rejected      3.559523          0.972335  20080        1.231286  ...   \n",
       "4       rejected      0.623163          0.650938  72323        0.188774  ...   \n",
       "\n",
       "  RwChosenVariance RwRejectedAverage  RwRejectedVariance RwDiffAverage  \\\n",
       "0         0.018304         -1.222914            0.024675      0.259599   \n",
       "1         0.018581         -0.579809            0.024868      1.808733   \n",
       "2         0.021960         -0.488183            0.020723      0.620937   \n",
       "3         0.016546         -2.121717            0.018112      3.213534   \n",
       "4         0.026763         -0.180517            0.026328      0.469449   \n",
       "\n",
       "   RwDiffVariance  RwVarianceSum  RwDiffAnalyticalVariance  PrefProbVariance  \\\n",
       "0        0.029189       0.042980                  0.029189          0.001746   \n",
       "1        0.019871       0.043450                  0.019871          0.000291   \n",
       "2        0.018558       0.042683                  0.018558          0.000957   \n",
       "3        0.030726       0.034659                  0.030726          0.000047   \n",
       "4        0.035856       0.053090                  0.035856          0.002010   \n",
       "\n",
       "  PrefProbAverage RewardMaxVariance  \n",
       "0        0.564097          0.024675  \n",
       "1        0.858371          0.024868  \n",
       "2        0.649819          0.021960  \n",
       "3        0.960816          0.018112  \n",
       "4        0.614342          0.026763  \n",
       "\n",
       "[5 rows x 311 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rewards.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf640704-6496-41b6-b1e7-e75f35f5d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ce(final_rewards):\n",
    "    final_rewards['Error'] = (final_rewards['PrefProbAverage'] < 0.5) * 1.0\n",
    "    final_rewards['GT'] = 1.0\n",
    "    final_rewards['CrossEntropy'] = kl_div(final_rewards['GT'], final_rewards['PrefProbAverage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39103ccb-b96e-472d-aa6a-004e6f4c77f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_ce(final_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f20035b6-cc5d-4259-9d18-4439f88cea69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>RewardChosen_0</th>\n",
       "      <th>Dataset_0</th>\n",
       "      <th>Preference_x_0</th>\n",
       "      <th>RewardRejected_0</th>\n",
       "      <th>Preference_y_0</th>\n",
       "      <th>RewardDiff_0</th>\n",
       "      <th>PreferenceProb_0</th>\n",
       "      <th>id</th>\n",
       "      <th>RewardChosen_1</th>\n",
       "      <th>...</th>\n",
       "      <th>RwDiffAverage</th>\n",
       "      <th>RwDiffVariance</th>\n",
       "      <th>RwVarianceSum</th>\n",
       "      <th>RwDiffAnalyticalVariance</th>\n",
       "      <th>PrefProbVariance</th>\n",
       "      <th>PrefProbAverage</th>\n",
       "      <th>RewardMaxVariance</th>\n",
       "      <th>Error</th>\n",
       "      <th>GT</th>\n",
       "      <th>CrossEntropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1801</td>\n",
       "      <td>-1.021655</td>\n",
       "      <td>train</td>\n",
       "      <td>chosen</td>\n",
       "      <td>-1.308317</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.286662</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>1801</td>\n",
       "      <td>-1.198608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259599</td>\n",
       "      <td>0.029189</td>\n",
       "      <td>0.042980</td>\n",
       "      <td>0.029189</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.564097</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.136626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87053</td>\n",
       "      <td>1.413000</td>\n",
       "      <td>train</td>\n",
       "      <td>chosen</td>\n",
       "      <td>-0.526894</td>\n",
       "      <td>rejected</td>\n",
       "      <td>1.939894</td>\n",
       "      <td>0.874340</td>\n",
       "      <td>87053</td>\n",
       "      <td>1.505481</td>\n",
       "      <td>...</td>\n",
       "      <td>1.808733</td>\n",
       "      <td>0.019871</td>\n",
       "      <td>0.043450</td>\n",
       "      <td>0.019871</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.858371</td>\n",
       "      <td>0.024868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59149</td>\n",
       "      <td>-0.104880</td>\n",
       "      <td>train</td>\n",
       "      <td>chosen</td>\n",
       "      <td>-0.680847</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.575967</td>\n",
       "      <td>0.640139</td>\n",
       "      <td>59149</td>\n",
       "      <td>0.134865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620937</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.042683</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.649819</td>\n",
       "      <td>0.021960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.080880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20080</td>\n",
       "      <td>1.230862</td>\n",
       "      <td>train</td>\n",
       "      <td>chosen</td>\n",
       "      <td>-2.328661</td>\n",
       "      <td>rejected</td>\n",
       "      <td>3.559523</td>\n",
       "      <td>0.972335</td>\n",
       "      <td>20080</td>\n",
       "      <td>1.231286</td>\n",
       "      <td>...</td>\n",
       "      <td>3.213534</td>\n",
       "      <td>0.030726</td>\n",
       "      <td>0.034659</td>\n",
       "      <td>0.030726</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.960816</td>\n",
       "      <td>0.018112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72323</td>\n",
       "      <td>0.448723</td>\n",
       "      <td>train</td>\n",
       "      <td>chosen</td>\n",
       "      <td>-0.174440</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.623163</td>\n",
       "      <td>0.650938</td>\n",
       "      <td>72323</td>\n",
       "      <td>0.188774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469449</td>\n",
       "      <td>0.035856</td>\n",
       "      <td>0.053090</td>\n",
       "      <td>0.035856</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.614342</td>\n",
       "      <td>0.026763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.101546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  RewardChosen_0 Dataset_0 Preference_x_0  RewardRejected_0  \\\n",
       "0   1801       -1.021655     train         chosen         -1.308317   \n",
       "1  87053        1.413000     train         chosen         -0.526894   \n",
       "2  59149       -0.104880     train         chosen         -0.680847   \n",
       "3  20080        1.230862     train         chosen         -2.328661   \n",
       "4  72323        0.448723     train         chosen         -0.174440   \n",
       "\n",
       "  Preference_y_0  RewardDiff_0  PreferenceProb_0     id  RewardChosen_1  ...  \\\n",
       "0       rejected      0.286662          0.571179   1801       -1.198608  ...   \n",
       "1       rejected      1.939894          0.874340  87053        1.505481  ...   \n",
       "2       rejected      0.575967          0.640139  59149        0.134865  ...   \n",
       "3       rejected      3.559523          0.972335  20080        1.231286  ...   \n",
       "4       rejected      0.623163          0.650938  72323        0.188774  ...   \n",
       "\n",
       "  RwDiffAverage RwDiffVariance  RwVarianceSum RwDiffAnalyticalVariance  \\\n",
       "0      0.259599       0.029189       0.042980                 0.029189   \n",
       "1      1.808733       0.019871       0.043450                 0.019871   \n",
       "2      0.620937       0.018558       0.042683                 0.018558   \n",
       "3      3.213534       0.030726       0.034659                 0.030726   \n",
       "4      0.469449       0.035856       0.053090                 0.035856   \n",
       "\n",
       "   PrefProbVariance  PrefProbAverage  RewardMaxVariance  Error   GT  \\\n",
       "0          0.001746         0.564097           0.024675    0.0  1.0   \n",
       "1          0.000291         0.858371           0.024868    0.0  1.0   \n",
       "2          0.000957         0.649819           0.021960    0.0  1.0   \n",
       "3          0.000047         0.960816           0.018112    0.0  1.0   \n",
       "4          0.002010         0.614342           0.026763    0.0  1.0   \n",
       "\n",
       "  CrossEntropy  \n",
       "0     0.136626  \n",
       "1     0.011090  \n",
       "2     0.080880  \n",
       "3     0.000788  \n",
       "4     0.101546  \n",
       "\n",
       "[5 rows x 314 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rewards.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a02dc7fc-9838-40bd-9b29-0d9da2e28f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(final_rewards, dataset_column):\n",
    "    train_df = final_rewards[final_rewards[dataset_column] == 'train']\n",
    "    test_df = final_rewards[final_rewards[dataset_column] == 'test']\n",
    "    eval_df = final_rewards[final_rewards[dataset_column] == 'eval']\n",
    "    ood_df = final_rewards[final_rewards[dataset_column] == 'ood']\n",
    "    return train_df, test_df, eval_df, ood_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbecc76f-4780-4b1b-a503-0c410199c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, eval_df, ood_df = split_dataset(final_rewards, \"Dataset_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0f7921-f990-4bba-b850-dd76cf4044b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a0147c7-fa96-4293-bedc-6ad4340b4322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.6882672519297213 1.7828431959087783\n",
      "-2.311974043781693 1.3708552275155041\n"
     ]
    }
   ],
   "source": [
    "def compute_quantiles(train_df):\n",
    "    chosen_p5 = train_df['RwChosenAverage'].quantile(0.05)\n",
    "    chosen_p95 = train_df['RwChosenAverage'].quantile(0.95)\n",
    "    \n",
    "    rej_p5 = train_df['RwRejectedAverage'].quantile(0.05)\n",
    "    rej_p95 = train_df['RwRejectedAverage'].quantile(0.95)\n",
    "    \n",
    "    print(chosen_p5, chosen_p95)\n",
    "    print(rej_p5, rej_p95)\n",
    "    return chosen_p5, chosen_p95, rej_p5, rej_p95\n",
    "\n",
    "def compute_outlier_unc(final_rewards, chosen_p5, chosen_p95, rej_p5, rej_p95):\n",
    "    # Heuristic: Get p5 and p95 in reward distributions (aka GDA)\n",
    "    final_rewards['TooHighOrTooLow'] = ((final_rewards['RwChosenAverage'] > chosen_p95) | (final_rewards['RwChosenAverage'] < chosen_p5) | (final_rewards['RwRejectedAverage'] < rej_p5) | (final_rewards['RwRejectedAverage'] > rej_p95)) * 1.0\n",
    "\n",
    "chosen_p5, chosen_p95, rej_p5, rej_p95 = compute_quantiles(train_df)\n",
    "compute_outlier_unc(final_rewards, chosen_p5, chosen_p95, rej_p5, rej_p95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "610ce576-11a9-4f68-9e9d-7066f04bb4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>RewardChosen_0</th>\n",
       "      <th>Dataset_0</th>\n",
       "      <th>Preference_x_0</th>\n",
       "      <th>RewardRejected_0</th>\n",
       "      <th>Preference_y_0</th>\n",
       "      <th>RewardDiff_0</th>\n",
       "      <th>PreferenceProb_0</th>\n",
       "      <th>id</th>\n",
       "      <th>RewardChosen_1</th>\n",
       "      <th>...</th>\n",
       "      <th>RwDiffVariance</th>\n",
       "      <th>RwVarianceSum</th>\n",
       "      <th>RwDiffAnalyticalVariance</th>\n",
       "      <th>PrefProbVariance</th>\n",
       "      <th>PrefProbAverage</th>\n",
       "      <th>RewardMaxVariance</th>\n",
       "      <th>Error</th>\n",
       "      <th>GT</th>\n",
       "      <th>CrossEntropy</th>\n",
       "      <th>TooHighOrTooLow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1801</td>\n",
       "      <td>-1.021655</td>\n",
       "      <td>train</td>\n",
       "      <td>chosen</td>\n",
       "      <td>-1.308317</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.286662</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>1801</td>\n",
       "      <td>-1.198608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029189</td>\n",
       "      <td>0.042980</td>\n",
       "      <td>0.029189</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.564097</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.136626</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87053</td>\n",
       "      <td>1.413000</td>\n",
       "      <td>train</td>\n",
       "      <td>chosen</td>\n",
       "      <td>-0.526894</td>\n",
       "      <td>rejected</td>\n",
       "      <td>1.939894</td>\n",
       "      <td>0.874340</td>\n",
       "      <td>87053</td>\n",
       "      <td>1.505481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019871</td>\n",
       "      <td>0.043450</td>\n",
       "      <td>0.019871</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.858371</td>\n",
       "      <td>0.024868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011090</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59149</td>\n",
       "      <td>-0.104880</td>\n",
       "      <td>train</td>\n",
       "      <td>chosen</td>\n",
       "      <td>-0.680847</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.575967</td>\n",
       "      <td>0.640139</td>\n",
       "      <td>59149</td>\n",
       "      <td>0.134865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.042683</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.649819</td>\n",
       "      <td>0.021960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.080880</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20080</td>\n",
       "      <td>1.230862</td>\n",
       "      <td>train</td>\n",
       "      <td>chosen</td>\n",
       "      <td>-2.328661</td>\n",
       "      <td>rejected</td>\n",
       "      <td>3.559523</td>\n",
       "      <td>0.972335</td>\n",
       "      <td>20080</td>\n",
       "      <td>1.231286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030726</td>\n",
       "      <td>0.034659</td>\n",
       "      <td>0.030726</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.960816</td>\n",
       "      <td>0.018112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72323</td>\n",
       "      <td>0.448723</td>\n",
       "      <td>train</td>\n",
       "      <td>chosen</td>\n",
       "      <td>-0.174440</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.623163</td>\n",
       "      <td>0.650938</td>\n",
       "      <td>72323</td>\n",
       "      <td>0.188774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035856</td>\n",
       "      <td>0.053090</td>\n",
       "      <td>0.035856</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.614342</td>\n",
       "      <td>0.026763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.101546</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  RewardChosen_0 Dataset_0 Preference_x_0  RewardRejected_0  \\\n",
       "0   1801       -1.021655     train         chosen         -1.308317   \n",
       "1  87053        1.413000     train         chosen         -0.526894   \n",
       "2  59149       -0.104880     train         chosen         -0.680847   \n",
       "3  20080        1.230862     train         chosen         -2.328661   \n",
       "4  72323        0.448723     train         chosen         -0.174440   \n",
       "\n",
       "  Preference_y_0  RewardDiff_0  PreferenceProb_0     id  RewardChosen_1  ...  \\\n",
       "0       rejected      0.286662          0.571179   1801       -1.198608  ...   \n",
       "1       rejected      1.939894          0.874340  87053        1.505481  ...   \n",
       "2       rejected      0.575967          0.640139  59149        0.134865  ...   \n",
       "3       rejected      3.559523          0.972335  20080        1.231286  ...   \n",
       "4       rejected      0.623163          0.650938  72323        0.188774  ...   \n",
       "\n",
       "  RwDiffVariance RwVarianceSum  RwDiffAnalyticalVariance PrefProbVariance  \\\n",
       "0       0.029189      0.042980                  0.029189         0.001746   \n",
       "1       0.019871      0.043450                  0.019871         0.000291   \n",
       "2       0.018558      0.042683                  0.018558         0.000957   \n",
       "3       0.030726      0.034659                  0.030726         0.000047   \n",
       "4       0.035856      0.053090                  0.035856         0.002010   \n",
       "\n",
       "   PrefProbAverage  RewardMaxVariance  Error   GT CrossEntropy TooHighOrTooLow  \n",
       "0         0.564097           0.024675    0.0  1.0     0.136626             0.0  \n",
       "1         0.858371           0.024868    0.0  1.0     0.011090             0.0  \n",
       "2         0.649819           0.021960    0.0  1.0     0.080880             0.0  \n",
       "3         0.960816           0.018112    0.0  1.0     0.000788             0.0  \n",
       "4         0.614342           0.026763    0.0  1.0     0.101546             0.0  \n",
       "\n",
       "[5 rows x 315 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rewards.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b0ba05c-8878-41a9-97f9-8decadfc032a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset\n",
      "Correlation Between Var(r1) + Var(r2) and Cross Entropy for train: 0.04154004075548281\n",
      "Correlation Between Var(r1-r2) and Cross Entropy for train: -0.09365878075551694\n",
      "Correlation Between Var(p) and Cross Entropy for train: 0.4840945267028453\n",
      "Correlation Between max(Var(r1), Var(r2)) and Cross Entropy for train: -0.013535195798154634\n",
      "Correlation Between Var(r1-r2, *) and Cross Entropy for train: 0.0415400321483095\n",
      "Correlation Between TooHighTooLow and Cross Entropy for train: 0.03256358691461575\n",
      "Test Dataset\n",
      "Correlation Between Var(r1) + Var(r2) and Cross Entropy for test: 0.01696573905824865\n",
      "Correlation Between Var(r1-r2) and Cross Entropy for test: -0.10864997466387988\n",
      "Correlation Between Var(p) and Cross Entropy for test: 0.322236670433129\n",
      "Correlation Between max(Var(r1), Var(r2)) and Cross Entropy for test: -0.03576840148701882\n",
      "Correlation Between Var(r1-r2, *) and Cross Entropy for test: 0.016966621773111475\n",
      "Correlation Between TooHighTooLow and Cross Entropy for test: 0.10736765676813996\n",
      "Eval Dataset\n",
      "Correlation Between Var(r1) + Var(r2) and Cross Entropy for eval: -0.00735990138875642\n",
      "Correlation Between Var(r1-r2) and Cross Entropy for eval: -0.0907103698705793\n",
      "Correlation Between Var(p) and Cross Entropy for eval: 0.30988203179789975\n",
      "Correlation Between max(Var(r1), Var(r2)) and Cross Entropy for eval: -0.037660075751052687\n",
      "Correlation Between Var(r1-r2, *) and Cross Entropy for eval: -0.007355355125315216\n",
      "Correlation Between TooHighTooLow and Cross Entropy for eval: 0.10285063046111902\n",
      "OOD Dataset\n",
      "Correlation Between Var(r1) + Var(r2) and Cross Entropy for ood: 0.13664201566288164\n",
      "Correlation Between Var(r1-r2) and Cross Entropy for ood: -0.030348968922563276\n",
      "Correlation Between Var(p) and Cross Entropy for ood: 0.22402185570435587\n",
      "Correlation Between max(Var(r1), Var(r2)) and Cross Entropy for ood: 0.10580599680610851\n",
      "Correlation Between Var(r1-r2, *) and Cross Entropy for ood: 0.1366409850465246\n",
      "Correlation Between TooHighTooLow and Cross Entropy for ood: 0.08439254880512294\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, eval_df, ood_df = split_dataset(final_rewards, \"Dataset_0\")\n",
    "# Compute Variances \n",
    "def compute_stats_ce_correlation(df, mode=\"train\", ensemble=True):\n",
    "    print(f\"Correlation Between Var(r1) + Var(r2) and Cross Entropy for {mode}: {df['RwVarianceSum'].corr(df['CrossEntropy'], method='spearman')}\")\n",
    "    print(f\"Correlation Between Var(r1-r2) and Cross Entropy for {mode}: {df['RwDiffVariance'].corr(df['CrossEntropy'], method='spearman')}\")\n",
    "    print(f\"Correlation Between Var(p) and Cross Entropy for {mode}: {df['PrefProbVariance'].corr(df['CrossEntropy'], method='spearman')}\")\n",
    "    print(f\"Correlation Between max(Var(r1), Var(r2)) and Cross Entropy for {mode}: {df['RewardMaxVariance'].corr(df['CrossEntropy'], method='spearman')}\")\n",
    "    if ensemble:\n",
    "        print(f\"Correlation Between Var(r1-r2, *) and Cross Entropy for {mode}: {df['RwDiffDistinctPairs'].corr(df['CrossEntropy'], method='spearman')}\")\n",
    "        print(f\"Correlation Between TooHighTooLow and Cross Entropy for {mode}: {df['TooHighOrTooLow'].corr(df['CrossEntropy'], method='spearman')}\")\n",
    "    \n",
    "print(\"Train Dataset\")\n",
    "compute_stats_ce_correlation(train_df, \"train\")\n",
    "print(\"Test Dataset\")\n",
    "compute_stats_ce_correlation(test_df, \"test\")\n",
    "print(\"Eval Dataset\")\n",
    "compute_stats_ce_correlation(eval_df, \"eval\")\n",
    "print(\"OOD Dataset\")\n",
    "compute_stats_ce_correlation(ood_df, \"ood\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41fc31-3181-45cb-9dee-c143b62c3890",
   "metadata": {},
   "source": [
    "# Baseline 2: Variational Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbba159e-4d0f-4771-9ab0-f6033f8da45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vpo_df = pd.read_csv('/users/lucelo/UQLRM/metadata_vpo.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a23d06a5-1349-4ce1-9536-1958a090bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_df = vpo_df[vpo_df['Preference'] == 'chosen'].rename(columns={'RewardScoreMean': 'RewardChosenMean', 'RewardScoreVar': 'RewardChosenVar'})\n",
    "rejected_df = vpo_df[vpo_df['Preference'] == 'rejected'].rename(columns={'RewardScoreMean': 'RewardRejectedMean', 'RewardScoreVar': 'RewardRejectedVar'})\n",
    "final_vpo_df = chosen_df.merge(rejected_df, on=['id', 'Dataset'], how='inner')\n",
    "final_vpo_df['RewardDiff'] = final_vpo_df['RewardChosenMean'] - final_vpo_df['RewardRejectedMean']\n",
    "final_vpo_df['PrefProbAverage'] = sigmoid(final_vpo_df['RewardDiff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1239816-b379-4897-99db-04625149dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rw_diff_var(x):\n",
    "    chosen_mu = x['RewardChosenMean']\n",
    "    chosen_var = x['RewardChosenVar']\n",
    "    chosen_points = np.random.normal(chosen_mu, np.sqrt(chosen_var), 1000)\n",
    "\n",
    "    rejected_mu = x['RewardRejectedMean']\n",
    "    rejected_var = x['RewardRejectedVar']\n",
    "    rejected_points = np.random.normal(rejected_mu, np.sqrt(rejected_var), 1000)\n",
    "\n",
    "    diff = chosen_points - rejected_points\n",
    "    probs = sigmoid(diff)\n",
    "    return pd.Series([np.mean(diff), np.var(diff), np.mean(probs), np.var(probs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ba4ee85-212d-444e-9fc5-dc87e5920b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preference_x</th>\n",
       "      <th>RewardChosenMean</th>\n",
       "      <th>RewardChosenVar</th>\n",
       "      <th>Model_x</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>id</th>\n",
       "      <th>Preference_y</th>\n",
       "      <th>RewardRejectedMean</th>\n",
       "      <th>RewardRejectedVar</th>\n",
       "      <th>Model_y</th>\n",
       "      <th>RewardDiff</th>\n",
       "      <th>PrefProbAverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chosen</td>\n",
       "      <td>0.217773</td>\n",
       "      <td>0.474215</td>\n",
       "      <td>vpo</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>-0.398438</td>\n",
       "      <td>0.459625</td>\n",
       "      <td>vpo</td>\n",
       "      <td>0.616211</td>\n",
       "      <td>0.649356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chosen</td>\n",
       "      <td>-1.054688</td>\n",
       "      <td>0.461424</td>\n",
       "      <td>vpo</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.122070</td>\n",
       "      <td>0.474215</td>\n",
       "      <td>vpo</td>\n",
       "      <td>-1.176758</td>\n",
       "      <td>0.235636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chosen</td>\n",
       "      <td>-0.306641</td>\n",
       "      <td>0.450735</td>\n",
       "      <td>vpo</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>rejected</td>\n",
       "      <td>-0.314453</td>\n",
       "      <td>0.457833</td>\n",
       "      <td>vpo</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.501953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chosen</td>\n",
       "      <td>-1.054688</td>\n",
       "      <td>0.461424</td>\n",
       "      <td>vpo</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>rejected</td>\n",
       "      <td>-0.445312</td>\n",
       "      <td>0.447228</td>\n",
       "      <td>vpo</td>\n",
       "      <td>-0.609375</td>\n",
       "      <td>0.352202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chosen</td>\n",
       "      <td>-1.054688</td>\n",
       "      <td>0.461424</td>\n",
       "      <td>vpo</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>rejected</td>\n",
       "      <td>-0.453125</td>\n",
       "      <td>0.454270</td>\n",
       "      <td>vpo</td>\n",
       "      <td>-0.601562</td>\n",
       "      <td>0.353986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Preference_x  RewardChosenMean  RewardChosenVar Model_x Dataset  id  \\\n",
       "0       chosen          0.217773         0.474215     vpo   train   0   \n",
       "1       chosen         -1.054688         0.461424     vpo   train   1   \n",
       "2       chosen         -0.306641         0.450735     vpo   train   2   \n",
       "3       chosen         -1.054688         0.461424     vpo   train   3   \n",
       "4       chosen         -1.054688         0.461424     vpo   train   4   \n",
       "\n",
       "  Preference_y  RewardRejectedMean  RewardRejectedVar Model_y  RewardDiff  \\\n",
       "0     rejected           -0.398438           0.459625     vpo    0.616211   \n",
       "1     rejected            0.122070           0.474215     vpo   -1.176758   \n",
       "2     rejected           -0.314453           0.457833     vpo    0.007812   \n",
       "3     rejected           -0.445312           0.447228     vpo   -0.609375   \n",
       "4     rejected           -0.453125           0.454270     vpo   -0.601562   \n",
       "\n",
       "   PrefProbAverage  \n",
       "0         0.649356  \n",
       "1         0.235636  \n",
       "2         0.501953  \n",
       "3         0.352202  \n",
       "4         0.353986  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vpo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24ec9abf-4273-4788-b1cc-c7d1756a397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unc_stats_vi(vpo_df):\n",
    "    # 4. Reward Diff (r_chosen - r_rejected) Statistics\n",
    "    vpo_df[['RwDiffAverage', 'RwDiffVariance', 'PrefProbAverage', 'PrefProbVariance']] = vpo_df.apply(lambda x: compute_rw_diff_var(x), axis=1)\n",
    "    \n",
    "    # 5. Variance Sum = Var(r_chosen) + Var(r_rejected)\n",
    "    vpo_df['RwVarianceSum'] = vpo_df['RewardChosenVar'] + vpo_df['RewardRejectedVar']\n",
    "    \n",
    "    # 8. Max Variance = max(Var(r_chosen), Var(r_rejected))\n",
    "    vpo_df['RewardMaxVariance'] = vpo_df[['RewardChosenVar', 'RewardRejectedVar']].max(axis=1)\n",
    "\n",
    "compute_unc_stats_vi(final_vpo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48fb29f5-36a0-47ce-b302-3365aa4dd822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preference_x</th>\n",
       "      <th>RewardChosenMean</th>\n",
       "      <th>RewardChosenVar</th>\n",
       "      <th>Model_x</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>id</th>\n",
       "      <th>Preference_y</th>\n",
       "      <th>RewardRejectedMean</th>\n",
       "      <th>RewardRejectedVar</th>\n",
       "      <th>Model_y</th>\n",
       "      <th>RewardDiff</th>\n",
       "      <th>PrefProbAverage</th>\n",
       "      <th>RwDiffAverage</th>\n",
       "      <th>RwDiffVariance</th>\n",
       "      <th>PrefProbVariance</th>\n",
       "      <th>RwVarianceSum</th>\n",
       "      <th>RewardMaxVariance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chosen</td>\n",
       "      <td>0.217773</td>\n",
       "      <td>0.474215</td>\n",
       "      <td>vpo</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>-0.398438</td>\n",
       "      <td>0.459625</td>\n",
       "      <td>vpo</td>\n",
       "      <td>0.616211</td>\n",
       "      <td>0.632254</td>\n",
       "      <td>0.641563</td>\n",
       "      <td>0.886410</td>\n",
       "      <td>0.035553</td>\n",
       "      <td>0.933841</td>\n",
       "      <td>0.474215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chosen</td>\n",
       "      <td>-1.054688</td>\n",
       "      <td>0.461424</td>\n",
       "      <td>vpo</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.122070</td>\n",
       "      <td>0.474215</td>\n",
       "      <td>vpo</td>\n",
       "      <td>-1.176758</td>\n",
       "      <td>0.271053</td>\n",
       "      <td>-1.177549</td>\n",
       "      <td>0.938799</td>\n",
       "      <td>0.028478</td>\n",
       "      <td>0.935640</td>\n",
       "      <td>0.474215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chosen</td>\n",
       "      <td>-0.306641</td>\n",
       "      <td>0.450735</td>\n",
       "      <td>vpo</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>rejected</td>\n",
       "      <td>-0.314453</td>\n",
       "      <td>0.457833</td>\n",
       "      <td>vpo</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.495338</td>\n",
       "      <td>-0.021880</td>\n",
       "      <td>0.895317</td>\n",
       "      <td>0.040108</td>\n",
       "      <td>0.908569</td>\n",
       "      <td>0.457833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chosen</td>\n",
       "      <td>-1.054688</td>\n",
       "      <td>0.461424</td>\n",
       "      <td>vpo</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>rejected</td>\n",
       "      <td>-0.445312</td>\n",
       "      <td>0.447228</td>\n",
       "      <td>vpo</td>\n",
       "      <td>-0.609375</td>\n",
       "      <td>0.375462</td>\n",
       "      <td>-0.606849</td>\n",
       "      <td>0.933827</td>\n",
       "      <td>0.037283</td>\n",
       "      <td>0.908652</td>\n",
       "      <td>0.461424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chosen</td>\n",
       "      <td>-1.054688</td>\n",
       "      <td>0.461424</td>\n",
       "      <td>vpo</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>rejected</td>\n",
       "      <td>-0.453125</td>\n",
       "      <td>0.454270</td>\n",
       "      <td>vpo</td>\n",
       "      <td>-0.601562</td>\n",
       "      <td>0.376867</td>\n",
       "      <td>-0.590886</td>\n",
       "      <td>0.881872</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.915695</td>\n",
       "      <td>0.461424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Preference_x  RewardChosenMean  RewardChosenVar Model_x Dataset  id  \\\n",
       "0       chosen          0.217773         0.474215     vpo   train   0   \n",
       "1       chosen         -1.054688         0.461424     vpo   train   1   \n",
       "2       chosen         -0.306641         0.450735     vpo   train   2   \n",
       "3       chosen         -1.054688         0.461424     vpo   train   3   \n",
       "4       chosen         -1.054688         0.461424     vpo   train   4   \n",
       "\n",
       "  Preference_y  RewardRejectedMean  RewardRejectedVar Model_y  RewardDiff  \\\n",
       "0     rejected           -0.398438           0.459625     vpo    0.616211   \n",
       "1     rejected            0.122070           0.474215     vpo   -1.176758   \n",
       "2     rejected           -0.314453           0.457833     vpo    0.007812   \n",
       "3     rejected           -0.445312           0.447228     vpo   -0.609375   \n",
       "4     rejected           -0.453125           0.454270     vpo   -0.601562   \n",
       "\n",
       "   PrefProbAverage  RwDiffAverage  RwDiffVariance  PrefProbVariance  \\\n",
       "0         0.632254       0.641563        0.886410          0.035553   \n",
       "1         0.271053      -1.177549        0.938799          0.028478   \n",
       "2         0.495338      -0.021880        0.895317          0.040108   \n",
       "3         0.375462      -0.606849        0.933827          0.037283   \n",
       "4         0.376867      -0.590886        0.881872          0.036079   \n",
       "\n",
       "   RwVarianceSum  RewardMaxVariance  \n",
       "0       0.933841           0.474215  \n",
       "1       0.935640           0.474215  \n",
       "2       0.908569           0.457833  \n",
       "3       0.908652           0.461424  \n",
       "4       0.915695           0.461424  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vpo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2dee467-e703-4e83-9be9-8daf415c24cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_ce(final_vpo_df)\n",
    "vpo_train_df, vpo_test_df, vpo_eval_df, vpo_ood_df = split_dataset(final_vpo_df, \"Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ce705a0-7dba-48aa-beb5-bac7fceca9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset\n",
      "Correlation Between Var(r1) + Var(r2) and Cross Entropy for train: -0.07272064067155334\n",
      "Correlation Between Var(r1-r2) and Cross Entropy for train: -0.03716236530827557\n",
      "Correlation Between Var(p) and Cross Entropy for train: 0.6614296494944618\n",
      "Correlation Between max(Var(r1), Var(r2)) and Cross Entropy for train: -0.09124672520223277\n",
      "Test Dataset\n",
      "Correlation Between Var(r1) + Var(r2) and Cross Entropy for test: -0.002000714114166764\n",
      "Correlation Between Var(r1-r2) and Cross Entropy for test: 0.0030218330206425678\n",
      "Correlation Between Var(p) and Cross Entropy for test: 0.47892330221793167\n",
      "Correlation Between max(Var(r1), Var(r2)) and Cross Entropy for test: -0.023795413147461395\n",
      "Eval Dataset\n",
      "Correlation Between Var(r1) + Var(r2) and Cross Entropy for eval: -0.03229438222276551\n",
      "Correlation Between Var(r1-r2) and Cross Entropy for eval: -0.009877164612702015\n",
      "Correlation Between Var(p) and Cross Entropy for eval: 0.45251092137986665\n",
      "Correlation Between max(Var(r1), Var(r2)) and Cross Entropy for eval: -0.05201663695200642\n",
      "OOD Dataset\n",
      "Correlation Between Var(r1) + Var(r2) and Cross Entropy for ood: 0.06624852197592024\n",
      "Correlation Between Var(r1-r2) and Cross Entropy for ood: 0.05597950177093523\n",
      "Correlation Between Var(p) and Cross Entropy for ood: 0.36932937182651315\n",
      "Correlation Between max(Var(r1), Var(r2)) and Cross Entropy for ood: 0.0654925829914813\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Dataset\")\n",
    "compute_stats_ce_correlation(vpo_train_df, \"train\", ensemble=False)\n",
    "print(\"Test Dataset\")\n",
    "compute_stats_ce_correlation(vpo_test_df, \"test\", ensemble=False)\n",
    "print(\"Eval Dataset\")\n",
    "compute_stats_ce_correlation(vpo_eval_df, \"eval\", ensemble=False)\n",
    "print(\"OOD Dataset\")\n",
    "compute_stats_ce_correlation(vpo_ood_df, \"ood\", ensemble=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebffd459-0093-4b59-a79c-934e5533134b",
   "metadata": {},
   "source": [
    "# Baseline 3: Finetuned Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cc9f5f6-a2d1-4d01-9fe8-0c53f9753e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(df):\n",
    "    return df.apply(lambda row: entropy(row), axis=1)\n",
    "    \n",
    "def compute_uncertanties(dfs):\n",
    "    # Compute single model entropies\n",
    "    for df in dfs:\n",
    "        df['entropy'] = compute_entropy(df[['First', 'Second']])\n",
    "    \n",
    "    \n",
    "    for i, df in enumerate(dfs):\n",
    "        # Add unique suffixes to the column names\n",
    "        df.columns = [f\"{col}_{i}\" if col != 'id' else col for col in df.columns]\n",
    "\n",
    "    # Use reduce to merge all dataframes\n",
    "    from functools import reduce\n",
    "    final_df = reduce(lambda left,right: pd.merge(left,right,on='id'), dfs)\n",
    "\n",
    "    first_cols = [col for col in final_df.columns if 'First_' in col]\n",
    "    second_cols = [col for col in final_df.columns if 'Second_' in col]\n",
    "    entropy_cols = [col for col in final_df.columns if 'entropy_' in col]\n",
    "\n",
    "    avg_first = final_df[first_cols].mean(axis=1)\n",
    "    avg_second = final_df[second_cols].mean(axis=1)\n",
    "    avg_entropy = final_df[entropy_cols].mean(axis=1)\n",
    "    var_first = final_df[first_cols].var(axis=1)\n",
    "    avg_df = pd.concat([avg_first, avg_second, avg_entropy, var_first], axis=1)\n",
    "    avg_df.columns = ['First', 'Second', 'Aleatoric Uncertainty', 'Variance']\n",
    "\n",
    "    \n",
    "    avg_df['Predictive Uncertainty'] = compute_entropy(avg_df[['First', 'Second']])\n",
    "    avg_df['Epistemic Uncertainty'] = avg_df['Predictive Uncertainty'] - avg_df['Aleatoric Uncertainty']\n",
    "    return avg_df['Epistemic Uncertainty'], avg_df['Predictive Uncertainty'], avg_df['Aleatoric Uncertainty'], avg_df[['First', 'Second']], avg_df['Variance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2b2c5c4-f4d1-4434-8508-b846ff320e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /scratch-ssd/oatml/huggingface/token\n",
      "Login successful\n",
      "Number of ensemble predictions loaded: 8\n",
      "Number of ensemble predictions loaded: 8\n",
      "Number of ensemble predictions loaded: 8\n",
      "Number of ensemble predictions loaded: 8\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token $HUGGINGFACE_WRITETOKEN\n",
    "def load_predictions(exp_prefix, name, checkpoint, mode, ensemble_size, active_learning=False):\n",
    "    ensemble_df = []\n",
    "    for j in range(ensemble_size):\n",
    "        if active_learning:\n",
    "            datafile = os.path.join(exp_prefix, f\"{name}\", \"predictions\", f\"{name}_{j}\", f\"checkpoint-{i}\", f\"eval_{mode}\", \"predictions.csv\")\n",
    "        else:\n",
    "            datafile = os.path.join(exp_prefix, f\"{name}_{j}\", f\"{name}_{j}\", f\"checkpoint-{i}\", f\"eval_{mode}\", \"predictions.csv\")\n",
    "        df = load_dataset(\"luckeciano/uqlrm_predictions\", data_files=datafile)['train'].to_pandas()\n",
    "        ensemble_df.append(df)\n",
    "\n",
    "\n",
    "    print(f\"Number of ensemble predictions loaded: {len(ensemble_df)}\")\n",
    "    epistemic, predictive, aleatoric, ens_predictions, var_predictions = compute_uncertanties(ensemble_df)\n",
    "    return ens_predictions, var_predictions\n",
    "    \n",
    "exp_prefix = \"scratch/lucelo/sft/results/\"\n",
    "name = \"gpt2_rwft_reddit_1\"\n",
    "i = 80\n",
    "train_ens_preds, train_var_preds = load_predictions(exp_prefix, name, i, \"train\", 8)\n",
    "test_ens_preds, test_var_preds = load_predictions(exp_prefix, name, i, \"test\", 8)\n",
    "eval_ens_preds, eval_var_preds = load_predictions(exp_prefix, name, i, \"eval\", 8)\n",
    "ood_ens_preds, ood_var_preds = load_predictions(exp_prefix, name, i, \"ood\", 8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fe1a230-3894-4bf9-9f69-1c64193aaf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ce_ens(ens_preds, var_preds):\n",
    "    finetune_ens_df = pd.DataFrame()\n",
    "    finetune_ens_df['PrefProbAverage'] = ens_preds['First']\n",
    "    finetune_ens_df['PrefProbVariance'] = var_preds\n",
    "    finetune_ens_df['Error'] = (finetune_ens_df['PrefProbAverage'] < 0.5) * 1.0\n",
    "    finetune_ens_df['GT'] = 1.0\n",
    "    finetune_ens_df['CrossEntropy'] = kl_div(finetune_ens_df['GT'], finetune_ens_df['PrefProbAverage'])\n",
    "    return finetune_ens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49e47355-c0c8-4a86-818e-92d318b79a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Between Var(p) and Cross Entropy for Training: 0.056321783544015507\n",
      "Correlation Between Var(p) and Cross Entropy for Training: 0.07439719985948799\n",
      "Correlation Between Var(p) and Cross Entropy for Training: 0.05166463652945645\n",
      "Correlation Between Var(p) and Cross Entropy for Training: -0.07087779592929311\n"
     ]
    }
   ],
   "source": [
    "train_df = compute_ce_ens(train_ens_preds, train_var_preds)\n",
    "print(f\"Correlation Between Var(p) and Cross Entropy for Training: {train_df['PrefProbVariance'].corr(train_df['CrossEntropy'], method='spearman')}\")\n",
    "\n",
    "test_df = compute_ce_ens(test_ens_preds, test_var_preds)\n",
    "print(f\"Correlation Between Var(p) and Cross Entropy for Training: {test_df['PrefProbVariance'].corr(test_df['CrossEntropy'], method='spearman')}\")\n",
    "\n",
    "eval_df = compute_ce_ens(eval_ens_preds, eval_var_preds)\n",
    "print(f\"Correlation Between Var(p) and Cross Entropy for Training: {eval_df['PrefProbVariance'].corr(eval_df['CrossEntropy'], method='spearman')}\")\n",
    "\n",
    "ood_df = compute_ce_ens(ood_ens_preds, ood_var_preds)\n",
    "print(f\"Correlation Between Var(p) and Cross Entropy for Training: {ood_df['PrefProbVariance'].corr(ood_df['CrossEntropy'], method='spearman')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f5068e9-b3d5-4e98-bb9e-6b0ecf75488e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ensemble predictions loaded: 8\n",
      "Number of ensemble predictions loaded: 8\n",
      "Number of ensemble predictions loaded: 8\n",
      "Number of ensemble predictions loaded: 8\n"
     ]
    }
   ],
   "source": [
    "exp_prefix = \"scratch/lucelo/active_learning/results/\"\n",
    "name = \"al_ep_v11_3\"\n",
    "i = 60\n",
    "train_ens_preds, train_var_preds = load_predictions(exp_prefix, name, i, \"train\", 8, active_learning=True)\n",
    "test_ens_preds, test_var_preds = load_predictions(exp_prefix, name, i, \"test\", 8, active_learning=True)\n",
    "eval_ens_preds, eval_var_preds = load_predictions(exp_prefix, name, i, \"eval\", 8, active_learning=True)\n",
    "ood_ens_preds, ood_var_preds = load_predictions(exp_prefix, name, i, \"ood\", 8, active_learning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78e626f1-c7f1-4d89-88c2-739891bfa615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Between Var(p) and Cross Entropy for Training: -0.09131798391076847\n",
      "Correlation Between Var(p) and Cross Entropy for Training: -0.014102754498991945\n",
      "Correlation Between Var(p) and Cross Entropy for Training: 0.006720589136532155\n",
      "Correlation Between Var(p) and Cross Entropy for Training: -0.11646054855009284\n"
     ]
    }
   ],
   "source": [
    "train_df = compute_ce_ens(train_ens_preds, train_var_preds)\n",
    "print(f\"Correlation Between Var(p) and Cross Entropy for Training: {train_df['PrefProbVariance'].corr(train_df['CrossEntropy'], method='spearman')}\")\n",
    "\n",
    "test_df = compute_ce_ens(test_ens_preds, test_var_preds)\n",
    "print(f\"Correlation Between Var(p) and Cross Entropy for Training: {test_df['PrefProbVariance'].corr(test_df['CrossEntropy'], method='spearman')}\")\n",
    "\n",
    "eval_df = compute_ce_ens(eval_ens_preds, eval_var_preds)\n",
    "print(f\"Correlation Between Var(p) and Cross Entropy for Training: {eval_df['PrefProbVariance'].corr(eval_df['CrossEntropy'], method='spearman')}\")\n",
    "\n",
    "ood_df = compute_ce_ens(ood_ens_preds, ood_var_preds)\n",
    "print(f\"Correlation Between Var(p) and Cross Entropy for Training: {ood_df['PrefProbVariance'].corr(ood_df['CrossEntropy'], method='spearman')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc44d17-8020-4398-811f-4d9e4d061007",
   "metadata": {},
   "source": [
    "# Baseline 4: Finetuned Ensembles with Different Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1db15aa-4c61-4d7c-a09b-f3592439dea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rw_set(filepath):\n",
    "    df = pd.read_csv(filepath, sep='\\t', header=0)[['id', 'RewardScore', 'Dataset', 'Preference']]\n",
    "    chosen_df = df[df['Preference'] == 'chosen'].rename(columns={'RewardScore': 'RewardChosen'})\n",
    "    rejected_df = df[df['Preference'] == 'rejected'].rename(columns={'RewardScore': 'RewardRejected'})\n",
    "    merged_df = chosen_df.merge(rejected_df, on=['id', 'Dataset'], how='inner')\n",
    "    merged_df['RewardDiff'] = merged_df['RewardChosen'] - merged_df['RewardRejected']\n",
    "    merged_df['PreferenceProb'] = sigmoid(merged_df['RewardDiff'])\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "687c1c0d-9794-4e7c-bbeb-37e1504dcbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2xl_df = generate_rw_set('/users/lucelo/UQLRM/uqlrm/scripts/slurm/metadata_gpt2xl-infer_.tsv')[['id', 'Dataset', 'RewardChosen', 'RewardRejected', 'RewardDiff', 'PreferenceProb']]\n",
    "gpt2xl_df.columns = [f\"{col}_gpt2xl\" if (col != 'id' and col != 'Dataset') else col for col in gpt2xl_df.columns]\n",
    "llama_df = generate_rw_set('/users/lucelo/UQLRM/uqlrm/scripts/slurm/metadata_llama_rw_infer_v0_.tsv')[['id', 'Dataset', 'RewardChosen', 'RewardRejected', 'RewardDiff', 'PreferenceProb']]\n",
    "llama_df.columns = [f\"{col}_llama\" if (col != 'id' and col != 'Dataset') else col for col in llama_df.columns]\n",
    "gpt2_df = generate_rw_set('/users/lucelo/UQLRM/metadata_gpt2-after-reward-modeling.tsv')[['id', 'Dataset', 'RewardChosen', 'RewardRejected', 'RewardDiff', 'PreferenceProb']]\n",
    "gpt2_df.columns = [f\"{col}_gpt2\" if (col != 'id' and col != 'Dataset') else col for col in gpt2_df.columns]\n",
    "hermes_df = generate_rw_set('/users/lucelo/UQLRM/metadata_single_mlp_0.tsv')[['id', 'Dataset', 'RewardChosen', 'RewardRejected', 'RewardDiff', 'PreferenceProb']]\n",
    "hermes_df.columns = [f\"{col}_hermes\" if (col != 'id' and col != 'Dataset') else col for col in hermes_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd47c4c3-230b-4586-a40f-d818c1e84530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>RewardChosen_gpt2xl</th>\n",
       "      <th>RewardRejected_gpt2xl</th>\n",
       "      <th>RewardDiff_gpt2xl</th>\n",
       "      <th>PreferenceProb_gpt2xl</th>\n",
       "      <th>RewardChosen_llama</th>\n",
       "      <th>RewardRejected_llama</th>\n",
       "      <th>RewardDiff_llama</th>\n",
       "      <th>PreferenceProb_llama</th>\n",
       "      <th>RewardChosen_hermes</th>\n",
       "      <th>RewardRejected_hermes</th>\n",
       "      <th>RewardDiff_hermes</th>\n",
       "      <th>PreferenceProb_hermes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1801</td>\n",
       "      <td>train</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>2.578125</td>\n",
       "      <td>-0.203125</td>\n",
       "      <td>0.449393</td>\n",
       "      <td>1.046875</td>\n",
       "      <td>-0.218750</td>\n",
       "      <td>1.265625</td>\n",
       "      <td>0.779993</td>\n",
       "      <td>-1.021655</td>\n",
       "      <td>-1.308317</td>\n",
       "      <td>0.286662</td>\n",
       "      <td>0.571179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87053</td>\n",
       "      <td>train</td>\n",
       "      <td>1.539062</td>\n",
       "      <td>0.636719</td>\n",
       "      <td>0.902344</td>\n",
       "      <td>0.711431</td>\n",
       "      <td>2.890625</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>2.382812</td>\n",
       "      <td>0.915507</td>\n",
       "      <td>1.413000</td>\n",
       "      <td>-0.526894</td>\n",
       "      <td>1.939894</td>\n",
       "      <td>0.874340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59149</td>\n",
       "      <td>train</td>\n",
       "      <td>1.953125</td>\n",
       "      <td>1.117188</td>\n",
       "      <td>0.835938</td>\n",
       "      <td>0.697609</td>\n",
       "      <td>-0.628906</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.035156</td>\n",
       "      <td>0.491212</td>\n",
       "      <td>-0.104880</td>\n",
       "      <td>-0.680847</td>\n",
       "      <td>0.575967</td>\n",
       "      <td>0.640139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20080</td>\n",
       "      <td>train</td>\n",
       "      <td>1.515625</td>\n",
       "      <td>-0.351562</td>\n",
       "      <td>1.867188</td>\n",
       "      <td>0.866133</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.482422</td>\n",
       "      <td>1.267578</td>\n",
       "      <td>0.780328</td>\n",
       "      <td>1.230862</td>\n",
       "      <td>-2.328661</td>\n",
       "      <td>3.559523</td>\n",
       "      <td>0.972335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72323</td>\n",
       "      <td>train</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.611382</td>\n",
       "      <td>2.218750</td>\n",
       "      <td>1.554688</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.660172</td>\n",
       "      <td>0.448723</td>\n",
       "      <td>-0.174440</td>\n",
       "      <td>0.623163</td>\n",
       "      <td>0.650938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id Dataset  RewardChosen_gpt2xl  RewardRejected_gpt2xl  \\\n",
       "0   1801   train             2.375000               2.578125   \n",
       "1  87053   train             1.539062               0.636719   \n",
       "2  59149   train             1.953125               1.117188   \n",
       "3  20080   train             1.515625              -0.351562   \n",
       "4  72323   train             0.960938               0.507812   \n",
       "\n",
       "   RewardDiff_gpt2xl  PreferenceProb_gpt2xl  RewardChosen_llama  \\\n",
       "0          -0.203125               0.449393            1.046875   \n",
       "1           0.902344               0.711431            2.890625   \n",
       "2           0.835938               0.697609           -0.628906   \n",
       "3           1.867188               0.866133            1.750000   \n",
       "4           0.453125               0.611382            2.218750   \n",
       "\n",
       "   RewardRejected_llama  RewardDiff_llama  PreferenceProb_llama  \\\n",
       "0             -0.218750          1.265625              0.779993   \n",
       "1              0.507812          2.382812              0.915507   \n",
       "2             -0.593750         -0.035156              0.491212   \n",
       "3              0.482422          1.267578              0.780328   \n",
       "4              1.554688          0.664062              0.660172   \n",
       "\n",
       "   RewardChosen_hermes  RewardRejected_hermes  RewardDiff_hermes  \\\n",
       "0            -1.021655              -1.308317           0.286662   \n",
       "1             1.413000              -0.526894           1.939894   \n",
       "2            -0.104880              -0.680847           0.575967   \n",
       "3             1.230862              -2.328661           3.559523   \n",
       "4             0.448723              -0.174440           0.623163   \n",
       "\n",
       "   PreferenceProb_hermes  \n",
       "0               0.571179  \n",
       "1               0.874340  \n",
       "2               0.640139  \n",
       "3               0.972335  \n",
       "4               0.650938  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df = pd.merge(gpt2xl_df, llama_df, on=['id', 'Dataset'], how='inner')\n",
    "# joined_df = pd.merge(joined_df, gpt2_df, on=['id', 'Dataset'], how='inner')\n",
    "joined_df = pd.merge(joined_df, hermes_df, on=['id', 'Dataset'], how='inner')\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0eab7d0c-ee7f-4ee4-8340-909e0357ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df['PrefProbVariance'] = joined_df.filter(like=\"PreferenceProb\", axis=1).var(axis=1)\n",
    "joined_df['PrefProbAverage'] = joined_df.filter(like=\"PreferenceProb\", axis=1).mean(axis=1)\n",
    "joined_df['RwDiffVariance'] = joined_df.filter(like=\"RewardDiff\", axis=1).var(axis=1)\n",
    "joined_df['GT'] = 1.0\n",
    "joined_df['Error'] = (joined_df['PrefProbAverage'] < 0.5) * 1.0\n",
    "joined_df['CrossEntropy'] = kl_div(joined_df['GT'], joined_df['PrefProbAverage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f16d222-553d-49df-9041-1a878255cd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>RewardChosen_gpt2xl</th>\n",
       "      <th>RewardRejected_gpt2xl</th>\n",
       "      <th>RewardDiff_gpt2xl</th>\n",
       "      <th>PreferenceProb_gpt2xl</th>\n",
       "      <th>RewardChosen_llama</th>\n",
       "      <th>RewardRejected_llama</th>\n",
       "      <th>RewardDiff_llama</th>\n",
       "      <th>PreferenceProb_llama</th>\n",
       "      <th>RewardChosen_hermes</th>\n",
       "      <th>RewardRejected_hermes</th>\n",
       "      <th>RewardDiff_hermes</th>\n",
       "      <th>PreferenceProb_hermes</th>\n",
       "      <th>PrefProbVariance</th>\n",
       "      <th>PrefProbAverage</th>\n",
       "      <th>RwDiffVariance</th>\n",
       "      <th>GT</th>\n",
       "      <th>Error</th>\n",
       "      <th>CrossEntropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1801</td>\n",
       "      <td>train</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>2.578125</td>\n",
       "      <td>-0.203125</td>\n",
       "      <td>0.449393</td>\n",
       "      <td>1.046875</td>\n",
       "      <td>-0.218750</td>\n",
       "      <td>1.265625</td>\n",
       "      <td>0.779993</td>\n",
       "      <td>-1.021655</td>\n",
       "      <td>-1.308317</td>\n",
       "      <td>0.286662</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>0.027955</td>\n",
       "      <td>0.600188</td>\n",
       "      <td>0.559248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87053</td>\n",
       "      <td>train</td>\n",
       "      <td>1.539062</td>\n",
       "      <td>0.636719</td>\n",
       "      <td>0.902344</td>\n",
       "      <td>0.711431</td>\n",
       "      <td>2.890625</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>2.382812</td>\n",
       "      <td>0.915507</td>\n",
       "      <td>1.413000</td>\n",
       "      <td>-0.526894</td>\n",
       "      <td>1.939894</td>\n",
       "      <td>0.874340</td>\n",
       "      <td>0.011647</td>\n",
       "      <td>0.833760</td>\n",
       "      <td>0.577412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59149</td>\n",
       "      <td>train</td>\n",
       "      <td>1.953125</td>\n",
       "      <td>1.117188</td>\n",
       "      <td>0.835938</td>\n",
       "      <td>0.697609</td>\n",
       "      <td>-0.628906</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.035156</td>\n",
       "      <td>0.491212</td>\n",
       "      <td>-0.104880</td>\n",
       "      <td>-0.680847</td>\n",
       "      <td>0.575967</td>\n",
       "      <td>0.640139</td>\n",
       "      <td>0.011347</td>\n",
       "      <td>0.609653</td>\n",
       "      <td>0.199977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20080</td>\n",
       "      <td>train</td>\n",
       "      <td>1.515625</td>\n",
       "      <td>-0.351562</td>\n",
       "      <td>1.867188</td>\n",
       "      <td>0.866133</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.482422</td>\n",
       "      <td>1.267578</td>\n",
       "      <td>0.780328</td>\n",
       "      <td>1.230862</td>\n",
       "      <td>-2.328661</td>\n",
       "      <td>3.559523</td>\n",
       "      <td>0.972335</td>\n",
       "      <td>0.009251</td>\n",
       "      <td>0.872932</td>\n",
       "      <td>1.412757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72323</td>\n",
       "      <td>train</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.611382</td>\n",
       "      <td>2.218750</td>\n",
       "      <td>1.554688</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.660172</td>\n",
       "      <td>0.448723</td>\n",
       "      <td>-0.174440</td>\n",
       "      <td>0.623163</td>\n",
       "      <td>0.650938</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.640831</td>\n",
       "      <td>0.012513</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id Dataset  RewardChosen_gpt2xl  RewardRejected_gpt2xl  \\\n",
       "0   1801   train             2.375000               2.578125   \n",
       "1  87053   train             1.539062               0.636719   \n",
       "2  59149   train             1.953125               1.117188   \n",
       "3  20080   train             1.515625              -0.351562   \n",
       "4  72323   train             0.960938               0.507812   \n",
       "\n",
       "   RewardDiff_gpt2xl  PreferenceProb_gpt2xl  RewardChosen_llama  \\\n",
       "0          -0.203125               0.449393            1.046875   \n",
       "1           0.902344               0.711431            2.890625   \n",
       "2           0.835938               0.697609           -0.628906   \n",
       "3           1.867188               0.866133            1.750000   \n",
       "4           0.453125               0.611382            2.218750   \n",
       "\n",
       "   RewardRejected_llama  RewardDiff_llama  PreferenceProb_llama  \\\n",
       "0             -0.218750          1.265625              0.779993   \n",
       "1              0.507812          2.382812              0.915507   \n",
       "2             -0.593750         -0.035156              0.491212   \n",
       "3              0.482422          1.267578              0.780328   \n",
       "4              1.554688          0.664062              0.660172   \n",
       "\n",
       "   RewardChosen_hermes  RewardRejected_hermes  RewardDiff_hermes  \\\n",
       "0            -1.021655              -1.308317           0.286662   \n",
       "1             1.413000              -0.526894           1.939894   \n",
       "2            -0.104880              -0.680847           0.575967   \n",
       "3             1.230862              -2.328661           3.559523   \n",
       "4             0.448723              -0.174440           0.623163   \n",
       "\n",
       "   PreferenceProb_hermes  PrefProbVariance  PrefProbAverage  RwDiffVariance  \\\n",
       "0               0.571179          0.027955         0.600188        0.559248   \n",
       "1               0.874340          0.011647         0.833760        0.577412   \n",
       "2               0.640139          0.011347         0.609653        0.199977   \n",
       "3               0.972335          0.009251         0.872932        1.412757   \n",
       "4               0.650938          0.000672         0.640831        0.012513   \n",
       "\n",
       "    GT  Error  CrossEntropy  \n",
       "0  1.0    0.0      0.110700  \n",
       "1  1.0    0.0      0.015570  \n",
       "2  1.0    0.0      0.104518  \n",
       "3  1.0    0.0      0.008830  \n",
       "4  1.0    0.0      0.085821  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69a3b8d2-186d-4749-a61e-d750e77067fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, eval_df, ood_df = split_dataset(joined_df, \"Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf1ba020-bd4e-4284-86a4-b3082ffc07eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Between Var(p) and Cross Entropy for Training: 0.23106520440146183\n",
      "Correlation Between Var(p) and Cross Entropy for OOD: 0.05782040031539965\n"
     ]
    }
   ],
   "source": [
    "print(f\"Correlation Between Var(p) and Cross Entropy for Training: {train_df['PrefProbVariance'].corr(train_df['CrossEntropy'], method='spearman')}\")\n",
    "\n",
    "print(f\"Correlation Between Var(p) and Cross Entropy for OOD: {ood_df['PrefProbVariance'].corr(ood_df['CrossEntropy'], method='spearman')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e7d51-fc79-49a3-aee4-94010ff00744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d2336f-5ad4-4607-bbeb-ef5d33c95b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
